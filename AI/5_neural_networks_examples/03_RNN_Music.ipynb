{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"03_RNN_Music.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"srXC6pLGLwS6"},"source":["<div style=\"width: 100%; clear: both;\">\n","<div style=\"float: left; width: 50%;\">\n","<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n","</div>\n","<p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.418 · Aprenentatge automàtic</p>\n","<p style=\"margin: 0; text-align:right;\">Grau en Ciència de Dades Aplicada</p>\n","<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis de Informàtica, Multimèdia i Telecomunicació</p>\n","</div>\n","</div>\n","<div style=\"width:100%;\">&nbsp;</div>\n","\n","\n","# Music generation with an RNN\n","\n","In this notebook we will learn how to generate music using a RNN.\n","\n","Our training data will be a MIDI sequence of [the Goldberg Variations of J.S. Bach](http://www.jsbach.net/midi/midi_goldbergvariations.html). Given a sequence of notes from this data, we will train a model to predict the next note in the sequence. Longer sequences of notes can be generated by calling the model repeatedly.\n","\n"," <img src=\"data:image/png;base64,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\">\n","\n"," <img src=\"data:image/png;base64,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\">"]},{"cell_type":"markdown","metadata":{"id":"ZgiOjXEm1-3X"},"source":["**Note**: Enable GPU acceleration to execute this notebook faster. In Colab: Runtime > Change runtime type > Hardware accelerator > GPU. \n","\n","**Note**: If you are running this in [a colab notebook](https://colab.research.google.com/), you should install the dependencies by running the following cell:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FZrFQxA1-3X","executionInfo":{"status":"ok","timestamp":1611166987347,"user_tz":-60,"elapsed":4279,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"475888e1-da1b-4fa7-c89c-02bde2dfa201"},"source":["! pip install numpy music21\n","! sudo apt-get install -qq timidity libsndfile1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n","Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.5.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WGyKZj3bzf9p"},"source":["### Import TensorFlow, Music21 and other libraries\n","\n","[Music21](http://web.mit.edu/music21/doc/index.html) is a Python-based toolkit for computer-aided musicology."]},{"cell_type":"code","metadata":{"id":"yG_n40gFzf9s","executionInfo":{"status":"ok","timestamp":1611166989129,"user_tz":-60,"elapsed":6025,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import time\n","\n","from music21 import *\n","\n","# Configure ipython to listen WAV files\n","from IPython.display import Audio"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EHDoRoc5PKWz"},"source":["### Download the J.S.Bach midi file (our training data)"]},{"cell_type":"code","metadata":{"id":"pD_55cOxLkAb","executionInfo":{"status":"ok","timestamp":1611166989132,"user_tz":-60,"elapsed":6011,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["path_to_file = tf.keras.utils.get_file('988-v01.mid', 'http://www.jsbach.net/midi/bwv988/988-v01.mid')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHjdCjDuSvX_"},"source":["### Read the data\n","\n","First, we will have a look in the midi stream:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aavnuByVymwK","executionInfo":{"status":"ok","timestamp":1611166989136,"user_tz":-60,"elapsed":5984,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"b136d45f-0f61-464b-ef01-021207df33e6"},"source":["# Read the MIDI file\n","mf = midi.MidiFile()\n","mf.open(path_to_file)\n","mf.read()\n","mf.close()\n","\n","# Convert midi data into a stream of notes\n","stream = midi.translate.midiFileToStream(mf)\n","\n","# We can also create a list of note names as follows\n","notes = [note.name for note in stream[0].notes]\n","print('Length of midi stream: {} notes'.format(len(notes)))\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Length of midi stream: 596 notes\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vOfSPHASB5E9"},"source":["A file with the .MID or .MIDI file extension is a Musical Instrument Digital Interface file. \n","\n","Unlike regular audio files like MP3s or WAVs, these don't contain actual audio data and are therefore much smaller in size. They instead explain what notes are played, when they're played, and how long or loud each note should be. \n","\n","When we read a MIDI file with the <code>music21</code> library we get a stream (a list) of notes in ABC notation. ABC notation is a shorthand form of musical notation. In basic form it uses the letters A through G to represent notes in the following way: \n","\n","'C' -> do, 'D' -> re, 'E' -> mi, 'F' -> fa, 'G' -> sol, 'A' -> la, 'B' -> si."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Duhg9NrUymwO","executionInfo":{"status":"ok","timestamp":1611166989141,"user_tz":-60,"elapsed":5963,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"443e60c7-5102-46b5-e32b-db662acfd577"},"source":["# Take a look at the first 10 note names in our training data stream\n","print(notes[:10])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['G', 'F#', 'G', 'D', 'E', 'F#', 'G', 'A', 'B', 'C#']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlCgQBRVymwR","executionInfo":{"status":"ok","timestamp":1611166989144,"user_tz":-60,"elapsed":5942,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"5ffa847a-c68b-4fd4-d834-f066851efd39"},"source":["# List all the unique note names in the stream\n","vocab_notes = sorted(set(notes))\n","print('{} unique notes'.format(len(vocab_notes)))\n","print(vocab_notes)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["11 unique notes\n","['A', 'B', 'C', 'C#', 'D', 'E', 'E-', 'F', 'F#', 'G', 'G#']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eJ9jYnz51-3d"},"source":["But musical notes have also a duration, this information is stored in the data we read as follows:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1Pmw05H1-3d","executionInfo":{"status":"ok","timestamp":1611166989778,"user_tz":-60,"elapsed":6547,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"44f3e958-73bc-45e5-950c-27821ec12be8"},"source":["# Take a look at the first 10 notes' duration in our training data stream\n","durations = [note.duration.quarterLength for note in stream[0].notes]\n","\n","print(durations[:10])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[0.25, 0.25, 0.75, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXYTbzpQ1-3e","executionInfo":{"status":"ok","timestamp":1611166989782,"user_tz":-60,"elapsed":6521,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"fe22476d-fcb6-4689-9b75-6614f76b45d6"},"source":["# List the unique notes' durations in the stream\n","vocab_durations = sorted(set(durations))\n","print('{} unique durations'.format(len(vocab_durations)))\n","print(vocab_durations)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["5 unique durations\n","[0.25, 0.5, 0.75, 1.0, 2.25]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y5HtBeTd1-3e"},"source":["Ideally we would like to have a model with two outputs at each time step: one for the note and the other for its duration. \n","\n","Here we will simplify this by considering the input/output elements of our RNN model to be a combination of a `note_name` and a `duration`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RUwuRd31-3e","executionInfo":{"status":"ok","timestamp":1611166989786,"user_tz":-60,"elapsed":6485,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"cdf739df-283c-4d2c-e569-6edfb869e429"},"source":["# The complete training data sequence is a list of notes (and their durations)\n","notes = [n.name+' '+str(n.duration.quarterLength) for n in stream[0].notes]*10 # repeat 10 times\n","\n","# The unique notes (and durations) in the stream\n","vocab = sorted(set(notes))\n","print('{} unique notes'.format(len(vocab)))\n","print(vocab)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["26 unique notes\n","['A 0.25', 'A 0.5', 'A 0.75', 'B 0.25', 'B 0.5', 'B 2.25', 'C 0.25', 'C 0.5', 'C 1.0', 'C# 0.25', 'D 0.25', 'D 0.5', 'D 0.75', 'D 1.0', 'E 0.25', 'E 0.5', 'E 0.75', 'E- 0.25', 'F 0.25', 'F# 0.25', 'F# 0.5', 'G 0.25', 'G 0.5', 'G 0.75', 'G 1.0', 'G# 0.25']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mvxJmAasGNud"},"source":["At every time step our model will predict one of those 26 unique notes using a one-hot vector representation as in a classification problem."]},{"cell_type":"markdown","metadata":{"id":"rNnrKn_lL-IJ"},"source":["## Process the music stream"]},{"cell_type":"markdown","metadata":{"id":"LFjSVAlWzf-N"},"source":["### Vectorize the notes\n","\n","Before training, you need to map notes (and durations) to a numerical representation. Create lookup tables mapping notes (and durations) to numbers, and numbers to notes (and durations)."]},{"cell_type":"code","metadata":{"id":"IalZLbvOzf-F","executionInfo":{"status":"ok","timestamp":1611166989788,"user_tz":-60,"elapsed":6463,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["# Creating a mapping from unique notes to indices\n","note2idx = {u:i for i, u in enumerate(vocab)}\n","idx2note = np.array(vocab)\n","\n","note_stream_as_int = np.array([note2idx[n] for n in notes])"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZfqhkYCymwX"},"source":["Now you have an integer representation (class label) for each note (and duration). Notice that you mapped the notes as indexes from 0 to `len(unique)`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYyNlCNXymwY","executionInfo":{"status":"ok","timestamp":1611166989792,"user_tz":-60,"elapsed":6448,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"b358043d-08b2-4b7a-c712-d835e94f9c7b"},"source":["print('{')\n","for note,_ in zip(note2idx, range(11)):\n","    print('  {:4s}: class {:3d},'.format(repr(note), note2idx[note]))\n","print('  ...\\n}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["{\n","  'A 0.25': class   0,\n","  'A 0.5': class   1,\n","  'A 0.75': class   2,\n","  'B 0.25': class   3,\n","  'B 0.5': class   4,\n","  'B 2.25': class   5,\n","  'C 0.25': class   6,\n","  'C 0.5': class   7,\n","  'C 1.0': class   8,\n","  'C# 0.25': class   9,\n","  'D 0.25': class  10,\n","  ...\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1VKcQHcymwb","executionInfo":{"status":"ok","timestamp":1611166989795,"user_tz":-60,"elapsed":6424,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"749688fc-e8fb-414c-bd76-cd9a0280e7b3"},"source":["# Show how the first 5 notes from the J.S.Bach MIDI stream are mapped to integers\n","print('{} ---- notes mapped to int ---- > {}'.format(repr(notes[:5]), note_stream_as_int[:5]))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['G 0.25', 'F# 0.25', 'G 0.75', 'D 0.25', 'E 0.25'] ---- notes mapped to int ---- > [21 19 23 10 14]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bbmsf23Bymwe"},"source":["### Define the prediction task"]},{"cell_type":"markdown","metadata":{"id":"wssHQ1oGymwe"},"source":["Given a note, or a sequence of notes, what is the most probable next note? This is the task we're training the model to perform. The input to the model will be a sequence of notes, and we will train the model to predict the output—the following note at each time step.\n","\n","Since RNNs maintain an internal state that depends on the previously seen elements, given all the notes computed until this moment, what is the next note?\n"]},{"cell_type":"markdown","metadata":{"id":"hgsVvVxnymwf"},"source":["### Create training examples and targets\n","\n","Next divide the notes' stream into example sequences. Each input sequence will contain `seq_length` notes from the stream.\n","\n","For each input sequence, the corresponding targets contain the same length of stream, except shifted one note to the right.\n","\n","So break the stream into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our stream is ['G', 'F#', 'G', 'D', 'E']. The input and output per time step would be as follow:\n","\n"," - t=0: input='G', output='F#'\n"," - t=1: input='F#', output='G' \n"," - t=2: input='G', ouput='D' \n"," - t=3: input='D', ouput='E' \n","\n","To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the notes vector into a stream of notes' indices."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UHJDA39zf-O","executionInfo":{"status":"ok","timestamp":1611166990542,"user_tz":-60,"elapsed":7146,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"4d93c087-82a1-450c-a68e-24023fe8e855"},"source":["# The maximum length sentence you want for a single input in notes\n","seq_length = 10\n","examples_per_epoch = len(notes)//(seq_length+1)\n","\n","# Create training examples / targets\n","note_dataset = tf.data.Dataset.from_tensor_slices(note_stream_as_int)\n","\n","for i in note_dataset.take(5):\n","    print(idx2note[i.numpy()])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["G 0.25\n","F# 0.25\n","G 0.75\n","D 0.25\n","E 0.25\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ZSYAcQV8OGP"},"source":["The `batch` method lets us easily convert these individual notes to sequences of the desired size."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4hkDU3i7ozi","executionInfo":{"status":"ok","timestamp":1611166990547,"user_tz":-60,"elapsed":7130,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"ab3f8bcf-3b50-488f-a621-05710f2c049d"},"source":["sequences = note_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for item in sequences.take(5):\n","    print(repr(' '.join(idx2note[item.numpy()])))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["'G 0.25 F# 0.25 G 0.75 D 0.25 E 0.25 F# 0.25 G 0.25 A 0.25 B 0.25 C# 0.25 D 0.25'\n","'C# 0.25 D 0.75 A 0.25 B 0.25 C# 0.25 D 0.25 E 0.25 F# 0.25 D 0.25 G 0.25 F# 0.25'\n","'G 0.75 F# 0.25 E 0.25 D 0.25 C# 0.25 E 0.25 A 0.25 G 0.25 F# 0.25 E 0.25 D 0.25'\n","'C# 0.25 D 0.25 F# 0.25 A 0.25 G 0.25 F# 0.25 A 0.25 D 0.5 D 0.25 C 0.25 D 0.5'\n","'G 0.5 B 0.5 D 0.5 E 0.25 D 0.25 E 0.5 A 0.5 C 0.5 E 0.5 F# 0.25 E 0.25'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UbLcIPBj_mWZ"},"source":["For each sequence, duplicate and shift it to form the input and target notes by using the `map` method to apply a simple function to each batch:"]},{"cell_type":"code","metadata":{"id":"9NGu-FkO_kYU","executionInfo":{"status":"ok","timestamp":1611166990550,"user_tz":-60,"elapsed":7111,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["def split_input_target(chunk):\n","    input_notes = chunk[:-1]\n","    target_notes = chunk[1:]\n","    return input_notes, target_notes\n","\n","dataset = sequences.map(split_input_target)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hiCopyGZymwi"},"source":["Print the first example input and target values:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNbw-iR0ymwj","executionInfo":{"status":"ok","timestamp":1611166990556,"user_tz":-60,"elapsed":7104,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"289b17c0-ca3c-4a31-bd87-70b94785cb9b"},"source":["for input_example, target_example in  dataset.take(1):\n","    print('Input data: ', repr(' '.join(idx2note[input_example.numpy()])))\n","    print('Target data:', repr(' '.join(idx2note[target_example.numpy()])))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Input data:  'G 0.25 F# 0.25 G 0.75 D 0.25 E 0.25 F# 0.25 G 0.25 A 0.25 B 0.25 C# 0.25'\n","Target data: 'F# 0.25 G 0.75 D 0.25 E 0.25 F# 0.25 G 0.25 A 0.25 B 0.25 C# 0.25 D 0.25'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_33OHL3b84i0"},"source":["Each index of these vectors is processed as a one time step. For the input at time step 0, the model receives the index for \"G\" and tries to predict the index for \"F#\" as the next note. At the next timestep, it does the same thing but the `RNN` considers the previous step context in addition to the current input note."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eBu9WZG84i0","executionInfo":{"status":"ok","timestamp":1611166990561,"user_tz":-60,"elapsed":7088,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"faa46a34-ef2c-4672-93bb-1ca34b9d06e9"},"source":["for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n","    print(\"Step {:4d}\".format(i))\n","    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2note[input_idx])))\n","    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2note[target_idx])))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Step    0\n","  input: 21 ('G 0.25')\n","  expected output: 19 ('F# 0.25')\n","Step    1\n","  input: 19 ('F# 0.25')\n","  expected output: 23 ('G 0.75')\n","Step    2\n","  input: 23 ('G 0.75')\n","  expected output: 10 ('D 0.25')\n","Step    3\n","  input: 10 ('D 0.25')\n","  expected output: 14 ('E 0.25')\n","Step    4\n","  input: 14 ('E 0.25')\n","  expected output: 19 ('F# 0.25')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MJdfPmdqzf-R"},"source":["### Create training batches\n","\n","You used `tf.data` to split the notes stream into manageable sequences. But before feeding this data into the model, you need to shuffle the data and pack it into batches."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2pGotuNzf-S","executionInfo":{"status":"ok","timestamp":1611166990563,"user_tz":-60,"elapsed":7068,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"41c32b54-8513-4af2-c70b-c44c2100d6a7"},"source":["# Batch size\n","BATCH_SIZE = 32\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","dataset"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset shapes: ((32, 10), (32, 10)), types: (tf.int64, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"r6oUuElIMgVx"},"source":["## Build The Model"]},{"cell_type":"markdown","metadata":{"id":"m8gPwEjRzf-Z"},"source":["Use `tf.keras.Sequential` to define the model. For this simple example three layers are used to define our model:\n","\n","* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map the numbers of each note to a vector with `embedding_dim` dimensions;\n","* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n","* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs."]},{"cell_type":"code","metadata":{"id":"zHT8cLh7EAsg","executionInfo":{"status":"ok","timestamp":1611166990567,"user_tz":-60,"elapsed":7051,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 128\n","\n","# Number of RNN units\n","rnn_units = 512"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtCrdfzEI2N0","executionInfo":{"status":"ok","timestamp":1611166990572,"user_tz":-60,"elapsed":7040,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                                  batch_input_shape=[batch_size, None]),\n","        tf.keras.layers.GRU(rnn_units,\n","                            return_sequences=True,\n","                            stateful=True,\n","                            recurrent_initializer='glorot_uniform'),\n","        tf.keras.layers.Dense(vocab_size)\n","    ])\n","    return model"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwsrpOik5zhv","executionInfo":{"status":"ok","timestamp":1611166990574,"user_tz":-60,"elapsed":7027,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["model = build_model(\n","    vocab_size=len(vocab),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units,\n","    batch_size=BATCH_SIZE)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RkA5upJIJ7W7"},"source":["For each note the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next note:\n"]},{"cell_type":"markdown","metadata":{"id":"-ubPo0_9Prjb"},"source":["## Try the model\n","\n","Now run the model to see that it behaves as expected.\n","\n","First check the shape of the output:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-_70kKAPrPU","executionInfo":{"status":"ok","timestamp":1611166992505,"user_tz":-60,"elapsed":8945,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"8c59c88c-dfd4-4a25-fef7-f913d26c041b"},"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["(32, 10, 26) # (batch_size, sequence_length, vocab_size)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q6NzLBi4VM4o"},"source":["In the above example the sequence length of the input is `10` but the model can be run on inputs of any length:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPGmAAXmVLGC","executionInfo":{"status":"ok","timestamp":1611166992515,"user_tz":-60,"elapsed":8920,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"a7e5987c-78cd-4f29-80d4-09bd21e5527c"},"source":["model.summary()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (32, None, 128)           3328      \n","_________________________________________________________________\n","gru (GRU)                    (32, None, 512)           986112    \n","_________________________________________________________________\n","dense (Dense)                (32, None, 26)            13338     \n","=================================================================\n","Total params: 1,002,778\n","Trainable params: 1,002,778\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uwv0gEkURfx1"},"source":["To get actual predictions from the model you need to sample from the output distribution, to get actual note indices. This distribution is defined by the logits over the notes vocabulary.\n","\n","**Note: It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.**\n","\n","Try it for the first example in the batch:"]},{"cell_type":"code","metadata":{"id":"4V4MfFg0RQJg","executionInfo":{"status":"ok","timestamp":1611166992521,"user_tz":-60,"elapsed":8906,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QM1Vbxs_URw5"},"source":["This gives us, at each timestep, a prediction of the next note index:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqFMUQc_UFgM","executionInfo":{"status":"ok","timestamp":1611166992528,"user_tz":-60,"elapsed":8899,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"fdecf06e-0828-445c-be39-54b33b430d86"},"source":["sampled_indices"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([18, 22, 11, 11,  7, 11, 25, 17, 24, 12])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"LfLtsP3mUhCG"},"source":["Decode these to see the notes predicted by this untrained model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWcFwPwLSo05","executionInfo":{"status":"ok","timestamp":1611166992532,"user_tz":-60,"elapsed":8882,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"01bd0a31-c744-44a2-ee1b-36f94a9f45c6"},"source":["print(\"Input: \\n\", repr(\" \".join([idx2note[n] for n in input_example_batch[0]])))\n","print()\n","print(\"Next Note Predictions: \\n\", repr(\" \".join(idx2note[sampled_indices])))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Input: \n"," 'D 0.25 G 0.25 B 0.25 G 0.25 F# 0.25 E 0.25 A 0.25 E 0.25 C# 0.25 A 0.25'\n","\n","Next Note Predictions: \n"," 'F 0.25 G 0.5 D 0.5 D 0.5 C 0.5 D 0.5 G# 0.25 E- 0.25 G 1.0 D 0.75'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LJL0Q0YPY6Ee"},"source":["## Train the model"]},{"cell_type":"markdown","metadata":{"id":"YCbHQHiaa4Ic"},"source":["At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next note."]},{"cell_type":"markdown","metadata":{"id":"trpqTWyvk0nr"},"source":["### Attach an optimizer, and a loss function"]},{"cell_type":"markdown","metadata":{"id":"UAjbjY03eiQ4"},"source":["The standard `tf.keras.losses.sparse_categorical_crossentropy` loss function works in this case because it is applied across the last dimension of the predictions.\n","\n","Because your model returns logits, you need to set the `from_logits` flag.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HrXTACTdzY-","executionInfo":{"status":"ok","timestamp":1611166992535,"user_tz":-60,"elapsed":8866,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"d0a761f9-e65e-4ade-9e4e-d6b3d7af9b18"},"source":["def loss(labels, logits):\n","    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","example_batch_loss = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Prediction shape:  (32, 10, 26)  # (batch_size, sequence_length, vocab_size)\n","scalar_loss:       3.2580342\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jeOXriLcymww"},"source":["Configure the training procedure using the `tf.keras.Model.compile` method. Use `tf.keras.optimizers.Adam` with default arguments and the loss function."]},{"cell_type":"code","metadata":{"id":"DDl1_Een6rL0","executionInfo":{"status":"ok","timestamp":1611166992541,"user_tz":-60,"elapsed":8850,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["model.compile(optimizer='adam', loss=loss)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjQvbxcj1-3p"},"source":["### Configure the checkpoints\n","\n","Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"]},{"cell_type":"code","metadata":{"id":"7xzMuiIe1-3p","executionInfo":{"status":"ok","timestamp":1611166992544,"user_tz":-60,"elapsed":8840,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Ky3F_BhgkTW"},"source":["### Execute the training"]},{"cell_type":"markdown","metadata":{"id":"IxdOA-rgyGvs"},"source":["To keep training time reasonable, use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UK-hmKjYVoll","executionInfo":{"status":"ok","timestamp":1611167023557,"user_tz":-60,"elapsed":39840,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"cf7e3b41-0cca-47ad-9387-5e5fa81d25f7"},"source":["history = model.fit(dataset, epochs=100, callbacks=[checkpoint_callback])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","16/16 [==============================] - 1s 5ms/step - loss: 3.1955\n","Epoch 2/100\n","16/16 [==============================] - 0s 5ms/step - loss: 2.8752\n","Epoch 3/100\n","16/16 [==============================] - 0s 5ms/step - loss: 2.4122\n","Epoch 4/100\n","16/16 [==============================] - 0s 5ms/step - loss: 2.1504\n","Epoch 5/100\n","16/16 [==============================] - 0s 5ms/step - loss: 1.9216\n","Epoch 6/100\n","16/16 [==============================] - 0s 4ms/step - loss: 1.7450\n","Epoch 7/100\n","16/16 [==============================] - 0s 5ms/step - loss: 1.5740\n","Epoch 8/100\n","16/16 [==============================] - 0s 5ms/step - loss: 1.4173\n","Epoch 9/100\n","16/16 [==============================] - 0s 5ms/step - loss: 1.2478\n","Epoch 10/100\n","16/16 [==============================] - 0s 5ms/step - loss: 1.1135\n","Epoch 11/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.9735\n","Epoch 12/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.8529\n","Epoch 13/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.7924\n","Epoch 14/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.7302\n","Epoch 15/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6766\n","Epoch 16/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6505\n","Epoch 17/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6411\n","Epoch 18/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6281\n","Epoch 19/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5983\n","Epoch 20/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5740\n","Epoch 21/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5784\n","Epoch 22/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5477\n","Epoch 23/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5590\n","Epoch 24/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5423\n","Epoch 25/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5386\n","Epoch 26/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5241\n","Epoch 27/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5136\n","Epoch 28/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5065\n","Epoch 29/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5165\n","Epoch 30/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5092\n","Epoch 31/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5121\n","Epoch 32/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5065\n","Epoch 33/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.5030\n","Epoch 34/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4941\n","Epoch 35/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4790\n","Epoch 36/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4864\n","Epoch 37/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.5063\n","Epoch 38/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4789\n","Epoch 39/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4697\n","Epoch 40/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4939\n","Epoch 41/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4730\n","Epoch 42/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4958\n","Epoch 43/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4531\n","Epoch 44/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4587\n","Epoch 45/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4522\n","Epoch 46/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4647\n","Epoch 47/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4837\n","Epoch 48/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4777\n","Epoch 49/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4831\n","Epoch 50/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4907\n","Epoch 51/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4594\n","Epoch 52/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4708\n","Epoch 53/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4623\n","Epoch 54/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4604\n","Epoch 55/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4602\n","Epoch 56/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4725\n","Epoch 57/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4640\n","Epoch 58/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4415\n","Epoch 59/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4616\n","Epoch 60/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4652\n","Epoch 61/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4761\n","Epoch 62/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4431\n","Epoch 63/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4476\n","Epoch 64/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4640\n","Epoch 65/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4488\n","Epoch 66/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4378\n","Epoch 67/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4664\n","Epoch 68/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4539\n","Epoch 69/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4364\n","Epoch 70/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4561\n","Epoch 71/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4432\n","Epoch 72/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4464\n","Epoch 73/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4387\n","Epoch 74/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4551\n","Epoch 75/100\n","16/16 [==============================] - 0s 4ms/step - loss: 0.4502\n","Epoch 76/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4672\n","Epoch 77/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4352\n","Epoch 78/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4324\n","Epoch 79/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4593\n","Epoch 80/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4340\n","Epoch 81/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4473\n","Epoch 82/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4256\n","Epoch 83/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4413\n","Epoch 84/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4436\n","Epoch 85/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4458\n","Epoch 86/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4265\n","Epoch 87/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4698\n","Epoch 88/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4431\n","Epoch 89/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4401\n","Epoch 90/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4331\n","Epoch 91/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4662\n","Epoch 92/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4475\n","Epoch 93/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4437\n","Epoch 94/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4429\n","Epoch 95/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4280\n","Epoch 96/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4371\n","Epoch 97/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4422\n","Epoch 98/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4351\n","Epoch 99/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4360\n","Epoch 100/100\n","16/16 [==============================] - 0s 5ms/step - loss: 0.4266\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kKkD5M6eoSiN"},"source":["## Generate music"]},{"cell_type":"markdown","metadata":{"id":"JIPcXllKjkdr"},"source":["### Restore the latest checkpoint"]},{"cell_type":"markdown","metadata":{"id":"LyeYRiuVjodY"},"source":["To keep this prediction step simple, use a batch size of 1.\n","\n","Because of the way the RNN state is passed from timestep to timestep, the model only accepts a fixed batch size once built.\n","\n","To run the model with a different `batch_size`, you need to rebuild the model and restore the weights from the checkpoint.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zk2WJ2-XjkGz","executionInfo":{"status":"ok","timestamp":1611167023568,"user_tz":-60,"elapsed":39831,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"cd8aa1ac-d342-41e6-c80c-2dc697021735"},"source":["tf.train.latest_checkpoint(checkpoint_dir)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./training_checkpoints/ckpt_100'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"LycQ-ot_jjyu","executionInfo":{"status":"ok","timestamp":1611167023902,"user_tz":-60,"elapsed":40146,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1, None]))"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71xa6jnYVrAN","executionInfo":{"status":"ok","timestamp":1611167023909,"user_tz":-60,"elapsed":40140,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"83468e7e-a5e5-4acc-ca53-afbecf1b3611"},"source":["model.summary()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (1, None, 128)            3328      \n","_________________________________________________________________\n","gru_1 (GRU)                  (1, None, 512)            986112    \n","_________________________________________________________________\n","dense_1 (Dense)              (1, None, 26)             13338     \n","=================================================================\n","Total params: 1,002,778\n","Trainable params: 1,002,778\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DjGz1tDkzf-u"},"source":["### The prediction loop\n","\n","The following code block generates the music stream:\n","\n","* Begin by choosing a start sequence of notes, initializing the RNN state and setting the number of notes to generate.\n","\n","* Get the prediction distribution of the next note using the start stream and the RNN state.\n","\n","* Then, use a categorical distribution to calculate the index of the predicted note. Use this predicted note as our next input to the model.\n","\n","* The RNN state returned by the model is fed back into the model so that it now has more context, instead of only one note. After predicting the next note, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted notes.\n"]},{"cell_type":"code","metadata":{"id":"WvuwZBX5Ogfd","executionInfo":{"status":"ok","timestamp":1611167023914,"user_tz":-60,"elapsed":40123,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":["def generate_music(model, start_seq):\n","    # Evaluation step (generating music using the learned model)\n","\n","    # Number of notes to generate\n","    num_generate = 100\n","\n","    # Converting our start string to numbers (vectorizing)\n","    input_eval = [note2idx[s] for s in start_seq]\n","    input_eval = tf.expand_dims(input_eval, 0)\n","\n","    # Empty list to store our results\n","    music_generated = []\n","\n","    # Low temperature results in more predictable music.\n","    # Higher temperature results in more surprising music.\n","    # Experiment to find the best setting.\n","    temperature = 1.0\n","\n","    # Here batch size == 1\n","    model.reset_states()\n","    for i in range(num_generate):\n","        predictions = model(input_eval)\n","        # remove the batch dimension\n","        predictions = tf.squeeze(predictions, 0)\n","\n","        # using a categorical distribution to predict the note returned by the model\n","        predictions = predictions / temperature\n","        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","        # Pass the predicted note as the next input to the model\n","        # along with the previous hidden state\n","        input_eval = tf.expand_dims([predicted_id], 0)\n","\n","        music_generated.append(idx2note[predicted_id])\n","\n","    return (start_seq + music_generated)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktovv0RFhrkn","executionInfo":{"status":"ok","timestamp":1611167024370,"user_tz":-60,"elapsed":40566,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"d961320d-0172-4448-f51b-846f177ac346"},"source":["generated_seq = generate_music(model, start_seq=['F# 0.25','G 0.75','D 0.25','E 0.25','F# 0.25','G 0.25'])\n","print(generated_seq)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["['F# 0.25', 'G 0.75', 'D 0.25', 'E 0.25', 'F# 0.25', 'G 0.25', 'A 0.25', 'B 0.25', 'C# 0.25', 'D 0.25', 'C# 0.25', 'D 0.75', 'A 0.25', 'B 0.25', 'C# 0.25', 'D 0.25', 'E 0.25', 'F# 0.25', 'D 0.25', 'G 0.25', 'F# 0.25', 'G 0.75', 'F# 0.25', 'E 0.25', 'D 0.25', 'C# 0.25', 'E 0.25', 'A 0.25', 'G 0.25', 'F# 0.25', 'E 0.25', 'D 0.25', 'C# 0.25', 'D 0.25', 'F# 0.25', 'A 0.25', 'G 0.25', 'F# 0.25', 'G 0.25', 'F# 0.25', 'A 0.25', 'D 0.25', 'F# 0.25', 'G 0.25', 'E 0.25', 'D 0.25', 'C# 0.25', 'F# 0.25', 'D 0.25', 'C# 0.25', 'B 0.25', 'A 0.25', 'G 0.25', 'F# 0.25', 'E 0.25', 'D 1.0', 'G 0.25', 'F# 0.25', 'G 0.75', 'D 0.25', 'E 0.25', 'F# 0.25', 'G 0.25', 'A 0.25', 'B 0.25', 'C# 0.25', 'D 0.25', 'C# 0.25', 'D 0.75', 'A 0.25', 'B 0.25', 'C# 0.25', 'D 0.25', 'E 0.25', 'F# 0.25', 'D 0.25', 'G 0.25', 'F# 0.25', 'G 0.75', 'F# 0.25', 'E 0.25', 'D 0.25', 'C# 0.25', 'E 0.25', 'A 0.25', 'G 0.25', 'F# 0.25', 'E 0.25', 'D 0.25', 'C# 0.25', 'G 0.25', 'E 0.25', 'C# 0.25', 'A 0.25', 'C# 0.25', 'E 0.25', 'G 0.25', 'C# 0.25', 'E 0.25', 'D 0.25', 'C# 0.25', 'D 0.5', 'F# 0.5', 'F# 0.5', 'A 0.5', 'D 0.5']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4sjP1zqp1-3r"},"source":["To listen the generated music we will create a new midi stream and play it:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189,"output_embedded_package_id":"10WBTgqzCcyr2GifUaqAccVoZWNzGdalC"},"id":"-vbjq_C21-3r","executionInfo":{"status":"ok","timestamp":1611167029091,"user_tz":-60,"elapsed":45261,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"bfbad8a7-4508-4bfc-c496-fdc95ed329e1"},"source":["from music21 import stream,note\n","generated_stream = stream.Stream() \n","\n","for n in generated_seq:\n","    \n","    myNote = note.Note(n.split(' ')[0])\n","    myNote.duration.quarterLength = float(n.split(' ')[1])\n","    generated_stream.append(myNote)\n","    \n","    \n","# show a midi player so we can listen the generated data\n","generated_stream.show('midi')\n","\n","# the previous command doesn't work in colab notebooks\n","# we must convert midi to WAV in order to listen it in colab\n","generated_stream.write('midi', fp='test_output.mid')\n","wav_from_midi = 'test_output.wav'\n","! timidity test_output.mid -Ow -o $wav_from_midi\n","Audio(wav_from_midi)"],"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"FzXINR8zGZVO","executionInfo":{"status":"ok","timestamp":1611167029100,"user_tz":-60,"elapsed":45250,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}},"outputId":"7ef3e675-6bb2-4abe-841f-fbc191ca53a1"},"source":["# Alternatively, you can download the midi file and reproduce it locally with a media player\r\n","from google.colab import files\r\n","files.download('test_output.mid') "],"execution_count":37,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_93f9a045-d4e3-4b50-8dc5-136911b2bc66\", \"test_output.mid\", 989)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"AM2Uma_-yVIq"},"source":["The easiest thing you can do to improve the results is to gather more training data (we are using a quite short sequence of only 600 notes for training) and/or to train it for longer (try `EPOCHS = 300`).\n","\n","You can also experiment with different start sequences, try adding another RNN layer to improve the model's accuracy, change the embedding dimension and/or the RNN number of units, or adjust the temperature parameter to generate more or less random predictions."]},{"cell_type":"code","metadata":{"id":"C_IXwhu31-3s","executionInfo":{"status":"ok","timestamp":1611167029111,"user_tz":-60,"elapsed":45242,"user":{"displayName":"Lluis Gomez Bigorda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnvGOFmTwjKcC4vDSfImcYiKVj1fxN5pS_cs8W=s64","userId":"01992071871552981599"}}},"source":[""],"execution_count":37,"outputs":[]}]}
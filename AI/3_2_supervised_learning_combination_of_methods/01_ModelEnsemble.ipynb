{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2 - Bagging","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1goSZkfi2rz4"},"source":["<div style=\"width: 100%; clear: both;\">\n","# Module 3: Example of bagging\n","\n","In this notebook, we will use the `BaggingClassifier` algorithm implemented in `scikit-learn` to create to classify the instances in the Iris flower dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"juQo1ZyD3MOz"},"source":["Let's import the required classes:"]},{"cell_type":"code","metadata":{"id":"r4_cH0N82L3F","executionInfo":{"status":"ok","timestamp":1610699852243,"user_tz":-60,"elapsed":918,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}}},"source":["# Import packages\n","from sklearn import datasets\n","from sklearn.linear_model import Perceptron\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sZcS6R903Pms"},"source":["Now, we load the data:"]},{"cell_type":"code","metadata":{"id":"Qu65HdP13XzC","executionInfo":{"status":"ok","timestamp":1610699852684,"user_tz":-60,"elapsed":1354,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}}},"source":["# Import data\n","iris = datasets.load_iris()\n","x = iris.data\n","y = iris.target"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3mumQr0P45nY"},"source":["And split in train and test:"]},{"cell_type":"code","metadata":{"id":"RNoEI_jY4gF7","executionInfo":{"status":"ok","timestamp":1610699852686,"user_tz":-60,"elapsed":1353,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}}},"source":["# Split train and test\n","xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.33, random_state=42)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0bFnKuG848Mx"},"source":["It's normally a good practice to check that the data you have is what you expected. Let's see the shape of our data:"]},{"cell_type":"code","metadata":{"id":"FxCYp1lC4-3h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610699852686,"user_tz":-60,"elapsed":1345,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}},"outputId":"79dff902-6994-450c-a2c4-9f6c7e06bbf3"},"source":["print('xtrain shape: ', xtrain.shape)\n","print('ytrain shape: ', xtrain.shape)\n","print('xtest shape: ', xtest.shape)\n","print('ytest shape: ', xtest.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["xtrain shape:  (100, 4)\n","ytrain shape:  (100, 4)\n","xtest shape:  (50, 4)\n","ytest shape:  (50, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gly7LTgt3ygg"},"source":["We will now create the classifier. In this notebook, we will use the `VotingClassifier` wrapper to combine 3 independent classifiers: `LogisticRegression`, `DecisionTreeClassifier` and `GaussianNB`.\n","\n","Let's create the 3 independent classifiers and combine them in an ensemble. We will use the default parameters for all of them, except for `LogisticRegression`, where we will increase the `max_iter` attribute to ensure convergence."]},{"cell_type":"code","metadata":{"id":"xtbpyu24Ea8T","executionInfo":{"status":"ok","timestamp":1610699852687,"user_tz":-60,"elapsed":1339,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}}},"source":["clf1 = Perceptron(random_state=1)\n","clf2 = Perceptron(random_state=2)\n","clf3 = Perceptron(random_state=3)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ME4ZDyZVFQbz"},"source":["As we saw in theory, there are two approaches for majority voting: hard and soft voting. We will run the examples with both of them. In addition, we will check how each classifier behaves independently.\n","\n","Let's check the models independently:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UluHL7oggv8v","executionInfo":{"status":"ok","timestamp":1610699852688,"user_tz":-60,"elapsed":1333,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}},"outputId":"ccff1b18-ab07-4073-f3ca-bdd8731233bd"},"source":["print('5-fold cross validation:\\n')\n","\n","labels = ['Perceptron'] * 3\n","\n","for clf, label in zip([clf1, clf2, clf3], labels):\n","\n","    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n","                                              cv=5, \n","                                              scoring='accuracy')\n","    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"\n","          % (scores.mean(), scores.std(), label))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["5-fold cross validation:\n","\n","Accuracy: 0.67 (+/- 0.13) [Perceptron]\n","Accuracy: 0.75 (+/- 0.08) [Perceptron]\n","Accuracy: 0.69 (+/- 0.14) [Perceptron]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tQMeNLnsK1U4"},"source":["Let's see with the ensemble of the three previous classifier and hard-voting:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RCFjx-8K6ED","executionInfo":{"status":"ok","timestamp":1610699853025,"user_tz":-60,"elapsed":1658,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}},"outputId":"a5f7fd8d-3ba3-498c-e469-f7bce82f6668"},"source":["model_ensemble = VotingClassifier(estimators=[\n","                                              ('1', clf1), \n","                                              ('2', clf2), \n","                                              ('3', clf3)\n","                                              ], voting='hard')\n","\n","label = 'Model ensemble'\n","scores = model_selection.cross_val_score(model_ensemble, xtrain, ytrain, cv=5, scoring='accuracy')\n","print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Accuracy: 0.77 (+/- 0.08) [Model ensemble]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vEzlXcP7Ln3n"},"source":["We could try doing the same with a soft voting. For that, we need a classifier that outputs probabilities as well as the categorical labels.\n","\n","We will use Naive Bayes in this example. Let's see what happens if we use the probabilities instead of the absolute class."]},{"cell_type":"code","metadata":{"id":"tcje-Y0eIeit","executionInfo":{"status":"ok","timestamp":1610699853026,"user_tz":-60,"elapsed":1651,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}}},"source":["clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1, random_state=0)\n","clf2 = MLPClassifier(hidden_layer_sizes=2, random_state=1, max_iter=1000)\n","clf3 = MLPClassifier(hidden_layer_sizes=2, random_state=10, max_iter=1000)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHmO_3UvLnQG","executionInfo":{"status":"ok","timestamp":1610699860019,"user_tz":-60,"elapsed":8641,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}},"outputId":"e5d341bf-6d5a-4506-b243-157d94faf793"},"source":["model_ensemble = VotingClassifier(estimators=[\n","                                              ('1', clf1), \n","                                              ('2', clf2), \n","                                              ('3', clf3)\n","                                              ], voting='soft',\n","                                              weights=[2, 1, 10])\n","\n","labels = ['Perceptron'] * 3 + ['Model ensemble']\n","for clf, label in zip([clf1, clf2, clf3, model_ensemble], labels):\n","\n","    scores = model_selection.cross_val_score(clf, xtrain, ytrain, \n","                                              cv=5, \n","                                              scoring='accuracy')\n","    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n","          % (scores.mean(), scores.std(), label))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Accuracy: 0.66 (+/- 0.02) [Perceptron]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy: 0.57 (+/- 0.11) [Perceptron]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy: 0.77 (+/- 0.04) [Perceptron]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy: 0.87 (+/- 0.07) [Model ensemble]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ft9DGUq8L7UW"},"source":["The warnings we get are to advise us that sciki-learn thinks that we did not reach convergence. In this example, the iterations are chosen intentionally to achieve the desired effect, but you should always pay attention to these warnings and think if you are correctly executing your model.\n","\n","As you can note, by combining the three models we are able to increase the accuracy of the model by 10% up to 87%. You can try different `weights` values and check how the results change."]},{"cell_type":"markdown","metadata":{"id":"DJhO3uxA3_XT"},"source":["And once we trained the ensemble, let's predict the labels for the test set:"]},{"cell_type":"code","metadata":{"id":"-AnMPKRr2U44","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610699869057,"user_tz":-60,"elapsed":1709,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}},"outputId":"c0544ca8-3906-4b27-827f-15cac15a0e82"},"source":["# Predict Output \n","model_ensemble.fit(xtrain, ytrain)\n","preds = model_ensemble.predict(xtest)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"EKcNdfcp4LKC"},"source":["Let's see the result. We'll compute the confusion matrix, which contains information about true positives/negatives and false positives/negatives"]},{"cell_type":"code","metadata":{"id":"cZyisM4Z2XdR","colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"status":"ok","timestamp":1610699872953,"user_tz":-60,"elapsed":923,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}},"outputId":"8ad6a85d-718d-4aac-9a2a-5dd1b4ebc47b"},"source":["# Plot Confusion Matrix\n","mat = confusion_matrix(preds, ytest)\n","names = np.unique(preds)\n","sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=names, yticklabels=names)\n","plt.xlabel('Truth')\n","plt.ylabel('Predicted')"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(89.18, 0.5, 'Predicted')"]},"metadata":{"tags":[]},"execution_count":24},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"O8RRLAVQOnvM","executionInfo":{"status":"ok","timestamp":1610699861487,"user_tz":-60,"elapsed":10085,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"","userId":"08557990006797564533"}}},"source":[""],"execution_count":22,"outputs":[]}]}
